{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change this constant and re-run to load a different source file. The file should be generated by the 'gatherTrace.sh' script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sourceFile = pathlib.Path('example.csv')\n",
    "sourceFile = pathlib.Path('data/2iter.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullDF = pd.read_csv(sourceFile, skiprows=[4], usecols=['Start', 'Duration', 'Size', 'Name'], dtype={'Start':float, 'Duration':float, 'Size':float, 'Name':str}, comment=\"=\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "#   All times will be ms\n",
    "#   All sizes with be MB\n",
    "# The CSV has the units as the second row\n",
    "\n",
    "# Start times are in S, duration is already ms\n",
    "fullDF['Start'] *= 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullDF['isKern'] = fullDF['Size'].isnull()\n",
    "kernDF = fullDF[ fullDF['isKern'] ]\n",
    "memDF = fullDF[ ~fullDF['isKern'] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Kernel Runtime:  0.052752990486714516 ms\n"
     ]
    }
   ],
   "source": [
    "avgKDur = kernDF['Duration'].mean()\n",
    "print(\"Average Kernel Runtime: \", avgKDur, \"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time between kernel invocations:  0.04443235494733129 ms\n"
     ]
    }
   ],
   "source": [
    "print(\"Average time between kernel invocations: \", kernDF['Start'].diff().mean(), \"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of runtime spent in GPU:  0.9942946433281026\n"
     ]
    }
   ],
   "source": [
    "# This isn't actuall the total time, it's just the time from the beginning to the last GPU function, there could be more time spent in the CPU-only end of the run.\n",
    "# TODO: collect more stats for runs from sources other than nvprof\n",
    "totalTime = fullDF['Start'].iloc[-1]\n",
    "totalKernTime = kernDF['Duration'].sum()\n",
    "print(\"Fraction of runtime spent in GPU: \", totalKernTime / totalTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average memcpy H->D size:  0.005816912391993873 MB\n",
      "Total memcpy H->D size:  425.47223999999983 MB\n",
      "Average memcpy H->D Duration:  0.002996896943016515 ms\n"
     ]
    }
   ],
   "source": [
    "memcpySizes = memDF[ memDF['Name'] == '[CUDA memcpy HtoD]' ][['Size','Duration']]\n",
    "print(\"Average memcpy H->D size: \", memcpySizes['Size'].mean(), 'MB')\n",
    "print(\"Total memcpy H->D size: \", memcpySizes['Size'].sum(), 'MB')\n",
    "print(\"Average memcpy H->D Duration: \", memcpySizes['Duration'].mean(), 'ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average memcpy D->H size:  Size        0.000004\n",
      "Duration    0.001822\n",
      "dtype: float64 MB\n",
      "Total memcpy D->H size:  Size        0.000992\n",
      "Duration    0.415467\n",
      "dtype: float64 MB\n",
      "Average memcpy H->D Duration:  0.0018222236842105265 ms\n"
     ]
    }
   ],
   "source": [
    "memcpySizes = memDF[ memDF['Name'] == '[CUDA memcpy DtoH]' ][['Size','Duration']]\n",
    "print(\"Average memcpy D->H size: \", memcpySizes.mean(), 'MB')\n",
    "print(\"Total memcpy D->H size: \", memcpySizes.sum(), 'MB')\n",
    "print(\"Average memcpy H->D Duration: \", memcpySizes['Duration'].mean(), 'ms')\n",
    "del memcpySizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interleaving of memory operations\n",
    "When multiple kernels run without an intervening memory operation, we can assume that they communicate through device memory (or use the transparent memory paging). This value is a good indicator of how many kernels we could pack into a single KaaS invocation. These traces don't capture host-side execution, so we can't be sure what is happening in between kernel invocations, but the average time between calls is small (see above) which would indicate that not much is going on. Still, it's possible that non-trivial synchronization or other calculations are occuring between invocations which would limit the kernel chain size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of runs kernels without interleaving memory ops:  150013\n",
      "Average run length:  4.2181010979048486\n"
     ]
    }
   ],
   "source": [
    "filt = fullDF['isKern']\n",
    "runGroups = pd.DataFrame({ 'group' : (filt != filt.shift(1)).cumsum()})\n",
    "runCounts = runGroups.groupby(by='group').size()\n",
    "del runGroups\n",
    "\n",
    "avgRunLen = runCounts.mean()\n",
    "print(\"Number of runs kernels without interleaving memory ops: \", len(runCounts))\n",
    "print(\"Average run length: \", avgRunLen)\n",
    "del runCounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated kernel chain duration (on average):  0.22251744708977453 ms\n"
     ]
    }
   ],
   "source": [
    "print(\"Estimated kernel chain duration (on average): \",  avgRunLen * avgKDur, 'ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
